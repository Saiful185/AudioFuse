{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b4cd6a92762452aaed2820ca9b774d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7d0505bb5ad4464a259d676db1be216",
              "IPY_MODEL_05674673dbd6443194cbd6b8c8e397f2",
              "IPY_MODEL_7f83f515d8ce4bff9ecfb12ec88ddbc6"
            ],
            "layout": "IPY_MODEL_4d009888fb5d43a1a35a39a224651098"
          }
        },
        "d7d0505bb5ad4464a259d676db1be216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0c6dc9fed54bd3964e77b2fe4b63b1",
            "placeholder": "​",
            "style": "IPY_MODEL_127f312555ae45758cf13ced382cbaf0",
            "value": "100%"
          }
        },
        "05674673dbd6443194cbd6b8c8e397f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f6cdb12e4c41b5a329b13d830d0857",
            "max": 3541,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd45f7f079f94d5786c8710dca70e8c9",
            "value": 3541
          }
        },
        "7f83f515d8ce4bff9ecfb12ec88ddbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea6be71ef3e64752a7e7253974789f12",
            "placeholder": "​",
            "style": "IPY_MODEL_a7f453a727694b57ac5877b56edd6573",
            "value": " 3541/3541 [3:16:48&lt;00:00,  3.27s/it]"
          }
        },
        "4d009888fb5d43a1a35a39a224651098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f0c6dc9fed54bd3964e77b2fe4b63b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127f312555ae45758cf13ced382cbaf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f6cdb12e4c41b5a329b13d830d0857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd45f7f079f94d5786c8710dca70e8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea6be71ef3e64752a7e7253974789f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7f453a727694b57ac5877b56edd6573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AudioFuse**"
      ],
      "metadata": {
        "id": "1gnriBJ5SvKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the preprocessing pipeline for our proposed **AudioFuse** and also its baseline models. We used the PhysioNet 2016 Challenge dataset (Heart Sound Classification/Abnormality Detection). The audio files were converted to Spectrograms and Scalograms here, creating 2-channel npy images. We also ensured no data leakage through data cleaning."
      ],
      "metadata": {
        "id": "oDZfAXtZSPX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing Libraries**"
      ],
      "metadata": {
        "id": "Q-tN916NRpvM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fCFOYx6Qxhb"
      },
      "outputs": [],
      "source": [
        "# File and Path Management\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "# Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Audio Processing\n",
        "import librosa\n",
        "import pywt # PyWavelets for scalogram\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Data Splitting and Metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    matthews_corrcoef,\n",
        "    cohen_kappa_score\n",
        ")\n",
        "\n",
        "# Utilities\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "import cv2 # OpenCV for resizing\n",
        "\n",
        "# Ensuring reproducible results\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Configuration**"
      ],
      "metadata": {
        "id": "HAs7SqJiSXar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    # --- Paths ---\n",
        "    ZIP_PATH = '/content/drive/MyDrive/Multimodal Audio Fusion/PhysioNet Heart Sound Classification.zip'\n",
        "    EXTRACT_PATH = '/content/physionet_data/'\n",
        "\n",
        "    # --- Audio Settings ---\n",
        "    SAMPLE_RATE = 22050\n",
        "    SIGNAL_LENGTH_SECONDS = 5\n",
        "    N_MELS = 224\n",
        "    N_FFT = 2048\n",
        "    HOP_LENGTH = 512\n",
        "    WAVELET = 'morl'\n",
        "\n",
        "    # --- Image/Input Settings ---\n",
        "    IMG_SIZE = 224\n",
        "    IN_CHANS = 1 # Each input stream is single-channel\n",
        "\n",
        "CONFIG = Config()"
      ],
      "metadata": {
        "id": "alXvgC0TSXtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preparation**"
      ],
      "metadata": {
        "id": "YFxoxn7OSQAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Unzipping the dataset ---\n",
        "if not os.path.exists(CONFIG.EXTRACT_PATH):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(CONFIG.ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(CONFIG.EXTRACT_PATH)\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n",
        "\n",
        "# --- 2. Helper function to load data from specific folders ---\n",
        "def load_data_from_folders(root_path, folder_patterns):\n",
        "    all_ref_files = []\n",
        "    for pattern in folder_patterns:\n",
        "        all_ref_files.extend(glob.glob(os.path.join(root_path, pattern, 'REFERENCE.csv')))\n",
        "\n",
        "    if not all_ref_files:\n",
        "        raise ValueError(f\"No REFERENCE.csv files found for patterns: {folder_patterns} in root: {root_path}\")\n",
        "\n",
        "    all_dfs = []\n",
        "    for ref_path in all_ref_files:\n",
        "        temp_df = pd.read_csv(ref_path, header=None, names=['filename', 'label'])\n",
        "        parent_dir = os.path.dirname(ref_path)\n",
        "        temp_df['filepath'] = temp_df['filename'].apply(\n",
        "            lambda fname: os.path.join(parent_dir, f\"{fname}.wav\")\n",
        "        )\n",
        "        all_dfs.append(temp_df)\n",
        "\n",
        "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    combined_df['label'] = combined_df['label'].apply(lambda x: 1 if x == 1 else 0)\n",
        "    return combined_df\n",
        "\n",
        "# --- 3. Loading the Training and Validation data separately ---\n",
        "DATA_ROOT = os.path.join(CONFIG.EXTRACT_PATH)\n",
        "train_folder_patterns = [\"training-*\"]\n",
        "validation_folder_patterns = [\"validation\"]\n",
        "\n",
        "try:\n",
        "    train_df = load_data_from_folders(DATA_ROOT, train_folder_patterns)\n",
        "    val_df = load_data_from_folders(DATA_ROOT, validation_folder_patterns)\n",
        "except ValueError:\n",
        "    print(\"Trying alternative directory structure...\")\n",
        "    DATA_ROOT = os.path.join(CONFIG.EXTRACT_PATH, \"physionet-cinc-challenge-2016-1.0.0\")\n",
        "    train_df = load_data_from_folders(DATA_ROOT, train_folder_patterns)\n",
        "    val_df = load_data_from_folders(DATA_ROOT, validation_folder_patterns)\n",
        "\n",
        "# Combining for pre-processing step\n",
        "data_df = pd.concat([train_df, val_df], ignore_index=True)\n",
        "\n",
        "print(f\"Total Training Samples: {len(train_df)}\")\n",
        "print(f\"Total Validation Samples: {len(val_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmNOImUnSQXF",
        "outputId": "110ef8b4-71e2-4853-cd25-18deac6e4f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "Extraction complete.\n",
            "Total Training Samples: 3240\n",
            "Total Validation Samples: 301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre-Computation and Saving Spectrogram + Scalogram .npy Files**"
      ],
      "metadata": {
        "id": "NXIdr4XcqsR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio processing functions with log-scaling for both\n",
        "def get_spectrogram(waveform, sr):\n",
        "    mel_spec = librosa.feature.melspectrogram(y=waveform, sr=sr, n_fft=CONFIG.N_FFT, hop_length=CONFIG.HOP_LENGTH, n_mels=CONFIG.N_MELS)\n",
        "    return librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "def get_scalogram(waveform):\n",
        "    scales = np.arange(1, CONFIG.N_MELS + 1)\n",
        "    coeffs, _ = pywt.cwt(waveform, scales, CONFIG.WAVELET)\n",
        "    return np.log1p(np.abs(coeffs))\n",
        "\n",
        "PROCESSED_DATA_DIR = \"/content/drive/MyDrive/Multimodal Audio Fusion/Physionet_processed_images/\"\n",
        "if not os.path.exists(PROCESSED_DATA_DIR):\n",
        "    os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
        "    print(\"Starting pre-computation of spectrograms and scalograms...\")\n",
        "\n",
        "    def process_and_save(filepath):\n",
        "        max_length = int(CONFIG.SIGNAL_LENGTH_SECONDS * CONFIG.SAMPLE_RATE)\n",
        "        waveform, _ = librosa.load(filepath, sr=CONFIG.SAMPLE_RATE, mono=True)\n",
        "        waveform = waveform[:max_length] if len(waveform) > max_length else np.pad(waveform, (0, max_length - len(waveform)), 'constant')\n",
        "\n",
        "        spec = get_spectrogram(waveform, CONFIG.SAMPLE_RATE)\n",
        "        spec_resized = cv2.resize(spec, (CONFIG.IMG_SIZE, CONFIG.IMG_SIZE))\n",
        "        spec_norm = (spec_resized - spec_resized.min()) / (spec_resized.max() - spec_resized.min() + 1e-6)\n",
        "\n",
        "        scalo = get_scalogram(waveform)\n",
        "        scalo_resized = cv2.resize(scalo, (CONFIG.IMG_SIZE, CONFIG.IMG_SIZE))\n",
        "        scalo_norm = (scalo_resized - scalo_resized.min()) / (scalo_resized.max() - scalo_resized.min() + 1e-6)\n",
        "\n",
        "        fused_image = np.stack([spec_norm, scalo_norm], axis=-1)\n",
        "        save_path = os.path.join(PROCESSED_DATA_DIR, f\"{os.path.splitext(os.path.basename(filepath))[0]}.npy\")\n",
        "        np.save(save_path, fused_image.astype(np.float32))\n",
        "        return save_path\n",
        "\n",
        "    data_df['npy_filepath'] = data_df['filepath'].progress_apply(process_and_save)\n",
        "    print(\"\\nPre-computation complete!\")\n",
        "else:\n",
        "    print(\"Pre-computed data found. Linking file paths...\")\n",
        "    data_df['npy_filepath'] = data_df['filename'].apply(lambda f: os.path.join(PROCESSED_DATA_DIR, f\"{f}.npy\"))\n",
        "\n",
        "# Updating train_df and val_df with the new .npy paths\n",
        "train_df = data_df[data_df['filename'].isin(train_df['filename'])].copy()\n",
        "val_df = data_df[data_df['filename'].isin(val_df['filename'])].copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "7b4cd6a92762452aaed2820ca9b774d0",
            "d7d0505bb5ad4464a259d676db1be216",
            "05674673dbd6443194cbd6b8c8e397f2",
            "7f83f515d8ce4bff9ecfb12ec88ddbc6",
            "4d009888fb5d43a1a35a39a224651098",
            "6f0c6dc9fed54bd3964e77b2fe4b63b1",
            "127f312555ae45758cf13ced382cbaf0",
            "21f6cdb12e4c41b5a329b13d830d0857",
            "bd45f7f079f94d5786c8710dca70e8c9",
            "ea6be71ef3e64752a7e7253974789f12",
            "a7f453a727694b57ac5877b56edd6573"
          ]
        },
        "id": "ZW8_gBKdqyvv",
        "outputId": "e9f70a90-a6dc-4e51-9cca-97c1f4db9af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting pre-computation of spectrograms and scalograms...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b4cd6a92762452aaed2820ca9b774d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3541 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pre-computation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Saving Final Metadata Files (No changes here) ---\n",
        "train_metadata_path = os.path.join(\"/content/drive/MyDrive/Multimodal Audio Fusion\", \"Heart Sounds_train.csv\")\n",
        "test_metadata_path = os.path.join(\"/content/drive/MyDrive/Multimodal Audio Fusion\", \"Heart Sounds_test.csv\")\n",
        "\n",
        "train_df.to_csv(train_metadata_path, index=False)\n",
        "val_df.to_csv(test_metadata_path, index=False)"
      ],
      "metadata": {
        "id": "LqM0KywPdKN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deleting Co-existing & Duplicate Entries in the Training and Validation Sets to Prevent Data Leakage**"
      ],
      "metadata": {
        "id": "oaikx0YTRQfJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7be83hqu9tSL",
        "outputId": "0cabe4ac-cbe1-451c-cb9c-7a7fe87dbffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the metadata files...\n",
            "\n",
            "--- Initial File Counts ---\n",
            "Original 'Heart Sounds_train.csv' rows: 2939\n",
            "Original 'Heart Sounds_test.csv' rows: 602\n",
            "\n",
            "--- Cleaning 'Heart Sounds_test.csv' ---\n",
            "Found 301 duplicate rows to remove.\n",
            "Cleaned 'Heart Sounds_test.csv' now has 301 unique rows.\n",
            "\n",
            "--- Cleaning 'Heart Sounds_train.csv' ---\n",
            "Found 0 rows in the training set that also exist in the test set. These will be removed.\n",
            "Cleaned 'Heart Sounds_train.csv' now has 2939 unique rows.\n",
            "\n",
            "Saving the cleaned files...\n",
            "--------------------------------------------------\n",
            "SUCCESS: Both metadata files have been cleaned and overwritten.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# --- 1. Defining File Paths ---\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/Multimodal Audio Fusion\"\n",
        "TRAIN_CSV_PATH = os.path.join(DRIVE_FOLDER, \"Heart Sounds_train.csv\")\n",
        "TEST_CSV_PATH = os.path.join(DRIVE_FOLDER, \"Heart Sounds_test.csv\")\n",
        "\n",
        "try:\n",
        "    # --- 2. Loading the CSV files ---\n",
        "    print(\"Loading the metadata files...\")\n",
        "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
        "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
        "\n",
        "    print(\"\\n--- Initial File Counts ---\")\n",
        "    print(f\"Original 'Heart Sounds_train.csv' rows: {len(train_df)}\")\n",
        "    print(f\"Original 'Heart Sounds_test.csv' rows: {len(test_df)}\")\n",
        "\n",
        "    # ================================================================\n",
        "    # Step 1: Cleaning the Test/Validation File (Heart Sounds_test.csv)\n",
        "    # ================================================================\n",
        "    print(\"\\n--- Cleaning 'Heart Sounds_test.csv' ---\")\n",
        "\n",
        "    # Identifying duplicates based on the unique audio file path\n",
        "    duplicates_in_test = test_df.duplicated(subset=['filename']).sum()\n",
        "    print(f\"Found {duplicates_in_test} duplicate rows to remove.\")\n",
        "\n",
        "    # Removing duplicates\n",
        "    cleaned_test_df = test_df.drop_duplicates(subset=['filename'], keep='first')\n",
        "\n",
        "    print(f\"Cleaned 'Heart Sounds_test.csv' now has {len(cleaned_test_df)} unique rows.\")\n",
        "\n",
        "    # ================================================================\n",
        "    # Step 2: Cleaning the Train File (Heart Sounds_train.csv)\n",
        "    # ================================================================\n",
        "    print(\"\\n--- Cleaning 'Heart Sounds_train.csv' ---\")\n",
        "\n",
        "    # Getting a list of all unique filepaths that are in the clean test set\n",
        "    test_filepaths = set(cleaned_test_df['filename'])\n",
        "\n",
        "    # Checking which rows in the training set are also in the test set\n",
        "    leaked_rows_mask = train_df['filename'].isin(test_filepaths)\n",
        "    leaked_rows_count = leaked_rows_mask.sum()\n",
        "    print(f\"Found {leaked_rows_count} rows in the training set that also exist in the test set. These will be removed.\")\n",
        "\n",
        "    # Keeping only the rows that are NOT in the test set\n",
        "    cleaned_train_df = train_df[~leaked_rows_mask]\n",
        "\n",
        "    print(f\"Cleaned 'Heart Sounds_train.csv' now has {len(cleaned_train_df)} unique rows.\")\n",
        "\n",
        "    # ================================================================\n",
        "    # Step 3: Overwriting the original files with the cleaned versions\n",
        "    # ================================================================\n",
        "    print(\"\\nSaving the cleaned files...\")\n",
        "\n",
        "    # Saving the cleaned data back to the original file paths\n",
        "    cleaned_train_df.to_csv(TRAIN_CSV_PATH, index=False)\n",
        "    cleaned_test_df.to_csv(TEST_CSV_PATH, index=False)\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(\"SUCCESS: Both metadata files have been cleaned and overwritten.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n--- ERROR ---\")\n",
        "    print(f\"Could not find a file. Please double-check the path and filename.\")\n",
        "    print(f\"The script was looking for: {e.filename}\")\n",
        "    print(\"-\" * 50)"
      ]
    }
  ]
}